---
type: literature-note
status: inmature
created at: 2024-10-27 11:22
updated at: 2024-10-27 11:22
category:
- technology
aliases: 
- Embedding Matrix
- We

---
Es la primera capa en la arquitectura de un [[Transformers|Transformer]]. Al momento de entrenar un [[LLMs|LLM]], se genera la [[Matriz de Embeddings]] que tiene 2 dimensiones: [[Tokens Vocabulary]] y  [[Embedding Dimension]]


---
## References

 - [How large language models work, a visual intro to transformers | Chapter 5, Deep Learning](https://www.youtube.com/watch?v=wjZofJX0v4M)

