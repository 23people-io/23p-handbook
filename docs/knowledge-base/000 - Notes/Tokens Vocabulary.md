---
type: literature-note
status: mature
created at: 2024-10-27 11:43
updated at: 2024-10-27 11:43
category:
- technology
aliases: 
- Vocabulario de Tokens

---
En un [[Transformers|Attention Transformer]],  corresponde a los distintos posibles [[Tokens]] que el LLM reconocerá al momento de entrenar o al hacer inferencias.

Por ejemplo, en [[GPT-3]], el tamaño era de 50.257 tokens posibles de reconocer.

---
## References

 - [How large language models work, a visual intro to transformers | Chapter 5, Deep Learning](https://www.youtube.com/watch?v=wjZofJX0v4M)

