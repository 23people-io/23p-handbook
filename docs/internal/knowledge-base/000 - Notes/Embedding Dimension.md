---
type: literature-note
status: inmature
created at: 2024-10-27 11:48
updated at: 2024-10-27 11:48
category:
- technology

---
En una [[Matriz de Embeddings]], corresponde a la dimensión que representa la cantidad de características que el modelo considerará por cada [[Tokens|Token]] en un espacio vectorial de alta dimensionalidad. 

Por ejemplo, en [[GPT-3]], la cantidad de características por cada Token era de 12.288

---
## References

 - [How large language models work, a visual intro to transformers | Chapter 5, Deep Learning](https://www.youtube.com/watch?v=wjZofJX0v4M)

